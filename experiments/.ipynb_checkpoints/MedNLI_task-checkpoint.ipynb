{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qybmgzLIOEXc"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zamfNyNrOz8_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gmichalo/umlsbert/UmlsBERT'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = !pwd\n",
    "ROOT_DIR = \"/\".join(ROOT_DIR[0].split(\"/\")[:-1])\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPdYFd_DSXxG"
   },
   "source": [
    "## Training Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08JAjMbxO3lN"
   },
   "outputs": [],
   "source": [
    "downstream_dir = ROOT_DIR + \"/text-classification/\"\n",
    "os.chdir(downstream_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TS4FahcnUcoT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/ee/fedc3509145ad60fe5b418783f4a4c1b5462a4f0e8c7bbdbda52bdcda486/tokenizers-0.8.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting sentencepiece\n",
      "  Using cached https://files.pythonhosted.org/packages/68/e5/0366f50a00db181f4b7f3bdc408fc7c4177657f5bf45cb799b79fb4ce15c/sentencepiece-0.1.92-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting sacremoses\n",
      "Collecting six (from sacremoses)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting joblib (from sacremoses)\n",
      "  Using cached https://files.pythonhosted.org/packages/51/dd/0e015051b4a27ec5a58b02ab774059f3289a94b0906f880a3f9507e74f38/joblib-0.16.0-py3-none-any.whl\n",
      "Collecting regex (from sacremoses)\n",
      "  Using cached https://files.pythonhosted.org/packages/3e/eb/85f375a102e95cde14a184ee985a35e1a20c4ceb3fe7f57fa128a9326283/regex-2020.7.14-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tqdm (from sacremoses)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/d5/f220e0c69b2f346b5649b66abebb391df1a00a59997a7ccf823325bd7a3e/tqdm-4.49.0-py2.py3-none-any.whl\n",
      "Collecting click (from sacremoses)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n",
      "Installing collected packages: tokenizers, sentencepiece, six, joblib, regex, tqdm, click, sacremoses\n",
      "Successfully installed click-7.1.2 joblib-0.16.0 regex-2020.7.14 sacremoses-0.0.43 sentencepiece-0.1.92 six-1.15.0 tokenizers-0.8.1 tqdm-4.49.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tokenizers sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3x8ii7X4TI-T"
   },
   "outputs": [],
   "source": [
    "def generate_command(config):\n",
    "  command = \"python3\"\n",
    "  command += \" \" + config[\"run_file\"] + \" \"\n",
    "  command += \"--output_dir \" + config[\"output_dir\"] + \" \"\n",
    "  command += \"--model_name_or_path \" + config[\"model_name_or_path\"] + \" \"\n",
    "  command += \"--data_dir \" + config[\"data_dir\"] + \" \"\n",
    "  command += \"--num_train_epochs \" + str(config[\"num_train_epochs\"]) + \" \"\n",
    "  command += \"--per_device_train_batch_size \" + str(config[\"per_device_train_batch_size\"]) + \" \"\n",
    "  command += \"--learning_rate \" + str(config[\"learning_rate\"]) + \" \"\n",
    "\n",
    "  if \"do_train\" in config:\n",
    "    command += \"--do_train \"\n",
    "  if \"do_eval\" in config:\n",
    "    command += \"--do_eval \"\n",
    "  if \"do_predict\" in config:\n",
    "    command += \"--do_predict \"\n",
    "\n",
    "  command += \"--seed \" + str(config[\"seed\"]) + \" \"\n",
    "  if \"umls\" in config:\n",
    "    command += \"--umls \"\n",
    "    command += \"--med_document \" + str(config[\"med_document\"]) + \" \"\n",
    "\n",
    "  command += \"--task_name \" + config[\"task_name\"]\n",
    "  command += \" --save_steps 5000\"\n",
    "  return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "############################################# \n",
    "Clinical/umls(both 1500000 and 3000000) BERT fine-tuning params\n",
    "- Output dir: ./models/clinicalBert-v1 | ./models/umls-clinicalBert-v1\n",
    "- model_name_or_path: emilyalsentzer/Bio_ClinicalBERT | ../checkpoint/clinicalbert300000\n",
    "- Learning Rate: {2e-5, 3e-5, 5e-5}\n",
    "- Batch size: {16, 32}\n",
    "- Epochs: {3, 4}\n",
    "############################################# \n",
    "'''\n",
    "\n",
    "# seeds = [6809, 36275, 5317, 82958, 25368] # five seeds average\n",
    "seeds = [6809] # fine tuning\n",
    "\n",
    "learning_rate_set = [2e-5, 3e-5, 5e-5]\n",
    "batch_size_set = [16, 32]\n",
    "epoch_set = [3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Clinical BERT and BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Z1feaIecRCC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'dataset/mednli/mednli/cache*': No such file or directory\n",
      "python3 run_glue.py --output_dir ./models/mednli/clinicalBert-6809-2020-09-13-23-26-53 --model_name_or_path emilyalsentzer/Bio_ClinicalBERT --data_dir dataset/mednli/mednli --num_train_epochs 3 --per_device_train_batch_size 32 --learning_rate 5e-05 --do_train --do_eval --do_predict --seed 6809 --task_name mnli --save_steps 5000\n",
      "python3 run_glue.py --output_dir ./models/mednli/BertBased-6809-2020-09-13-23-27-47 --model_name_or_path bert-base-cased --data_dir dataset/mednli/mednli --num_train_epochs 3 --per_device_train_batch_size 32 --learning_rate 5e-05 --do_train --do_eval --do_predict --seed 6809 --task_name mnli --save_steps 5000\n"
     ]
    }
   ],
   "source": [
    "path_set = [\n",
    "    (\"./models/mednli/clinicalBert\", \"emilyalsentzer/Bio_ClinicalBERT\"), \n",
    "    (\"./models/mednli/BertBased\", \"bert-base-cased\")\n",
    "]\n",
    "\n",
    "for seed in seeds:\n",
    "    for lr in learning_rate_set:\n",
    "        for epoch in epoch_set:\n",
    "            for batch_size in batch_size_set:\n",
    "                for path in path_set:\n",
    "                    config = {\n",
    "                    \"run_file\"                    :     \"run_glue.py\",\n",
    "                    \"output_dir\"                  :     path[0] + \"-\" +  str(seed)+\"-\"+ datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"),\n",
    "                    \"model_name_or_path\"          :     path[1],\n",
    "                    \"data_dir\"                    :     \"dataset/mednli/mednli\",\n",
    "                    \"num_train_epochs\"            :     epoch,\n",
    "                    \"seed\"                        :     seed,\n",
    "                    \"per_device_train_batch_size\" :     batch_size,\n",
    "                    \"learning_rate\"               :     lr,\n",
    "                    \"do_train\"                    :     True,\n",
    "                    \"do_eval\"                     :     True,\n",
    "                    \"do_predict\"                  :     True,\n",
    "                    \"task_name\"                   :     \"mnli\"\n",
    "                    }\n",
    "\n",
    "                    # Run Downstream tasks with given config\n",
    "                    !rm dataset/mednli/mednli/cache*\n",
    "                    command = generate_command(config)\n",
    "                    print(command)\n",
    "                    subprocess.call(command, shell=True)\n",
    "\n",
    "                    # Save config to output dir\n",
    "                    with open(config[\"output_dir\"] + '/fine_tune_config.json', 'w') as f:\n",
    "                        json.dump(config, f)\n",
    "                    assert \"fine_tune_config.json\" in os.listdir(config[\"output_dir\"])\n",
    "\n",
    "                    # delete all checkpoints\n",
    "                    for path in os.listdir(config[\"output_dir\"]):\n",
    "                        if path.startswith(\"checkpoint\"):\n",
    "                            shutil.rmtree(config[\"output_dir\"] + \"/\" +path)\n",
    "                        if path.startswith(\"pytorch_model.bin\"):\n",
    "                            os.remove(config[\"output_dir\"] + \"/\" +path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune UMLS Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 run_glue.py --output_dir ./models/mednli/umlsbert-6809-2020-09-13-23-28-41 --model_name_or_path ../checkpoint/umlsbert --data_dir dataset/mednli/mednli --num_train_epochs 3 --per_device_train_batch_size 32 --learning_rate 5e-05 --do_train --do_eval --do_predict --seed 6809 --umls --med_document voc/vocab_updated.txt --task_name mnli --save_steps 5000\n"
     ]
    }
   ],
   "source": [
    "path_set = [(\"./models/mednli/umlsbert\", \"../checkpoint/umlsbert\")]\n",
    "\n",
    "for seed in seeds:\n",
    "  for lr in learning_rate_set:\n",
    "    for epoch in epoch_set:\n",
    "      for batch_size in batch_size_set:\n",
    "        for path in path_set:\n",
    "          config = {\n",
    "              \"run_file\"                    :     \"run_glue.py\",\n",
    "              \"output_dir\"                  :     path[0] + \"-\" +  str(seed)+\"-\"+ datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"),\n",
    "              \"model_name_or_path\"          :     path[1],\n",
    "              \"data_dir\"                    :     \"dataset/mednli/mednli\",\n",
    "              \"num_train_epochs\"            :     epoch,\n",
    "              \"seed\"                        :     seed,\n",
    "              \"per_device_train_batch_size\" :     batch_size,\n",
    "              \"learning_rate\"               :     lr,\n",
    "              \"do_train\"                    :     True,\n",
    "              \"do_eval\"                     :     True,\n",
    "              \"do_predict\"                  :     True,\n",
    "              \"umls\"                        :     True,\n",
    "              \"med_document\"                :     \"voc/vocab_updated.txt\",\n",
    "              \"task_name\"                   :     \"mnli\"\n",
    "          }\n",
    "          \n",
    "          # Run Downstream tasks with given config\n",
    "          !rm dataset/mednli/mednli/cache*\n",
    "          command = generate_command(config)\n",
    "          print(command)\n",
    "          subprocess.run(command, shell=True)\n",
    "\n",
    "          # Save config to output dir\n",
    "          with open(config[\"output_dir\"] + '/fine_tune_config.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "          assert \"fine_tune_config.json\" in os.listdir(config[\"output_dir\"])\n",
    "\n",
    "          # delete all checkpoints\n",
    "          for path in os.listdir(config[\"output_dir\"]):\n",
    "            if path.startswith(\"checkpoint\"):\n",
    "              shutil.rmtree(config[\"output_dir\"] + \"/\" +path)\n",
    "            if path.startswith(\"pytorch_model.bin\"):\n",
    "              os.remove(config[\"output_dir\"] + \"/\" +path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab_UMLS_MedNLI.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
