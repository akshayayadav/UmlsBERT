{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3899,
     "status": "ok",
     "timestamp": 1594600157661,
     "user": {
      "displayName": "kaxalein M",
      "photoUrl": "",
      "userId": "08160306184891523165"
     },
     "user_tz": 240
    },
    "id": "qybmgzLIOEXc",
    "outputId": "2f436b29-d635-4e69-fa68-4b7883d8733e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import seqeval\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5936,
     "status": "ok",
     "timestamp": 1594600159726,
     "user": {
      "displayName": "kaxalein M",
      "photoUrl": "",
      "userId": "08160306184891523165"
     },
     "user_tz": 240
    },
    "id": "zamfNyNrOz8_",
    "outputId": "8a196fe3-7c44-427d-8808-badc752667e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gmichalo/umlsbert/UmlsBERT'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = !pwd\n",
    "ROOT_DIR = \"/\".join(ROOT_DIR[0].split(\"/\")[:-1])\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPdYFd_DSXxG"
   },
   "source": [
    "## Training Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9959,
     "status": "ok",
     "timestamp": 1594600163763,
     "user": {
      "displayName": "kaxalein M",
      "photoUrl": "",
      "userId": "08160306184891523165"
     },
     "user_tz": 240
    },
    "id": "08JAjMbxO3lN",
    "outputId": "e41ed7b0-53d7-43af-d1db-dcc8de05260d"
   },
   "outputs": [],
   "source": [
    "downstream_dir = ROOT_DIR + \"/token-classification/\"\n",
    "os.chdir(downstream_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13151,
     "status": "ok",
     "timestamp": 1594600166967,
     "user": {
      "displayName": "kaxalein M",
      "photoUrl": "",
      "userId": "08160306184891523165"
     },
     "user_tz": 240
    },
    "id": "TS4FahcnUcoT",
    "outputId": "369e8bcb-03ca-4801-d3fa-9d12df0ab0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pip: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14069,
     "status": "ok",
     "timestamp": 1594600167902,
     "user": {
      "displayName": "kaxalein M",
      "photoUrl": "",
      "userId": "08160306184891523165"
     },
     "user_tz": 240
    },
    "id": "3x8ii7X4TI-T"
   },
   "outputs": [],
   "source": [
    "def generate_command(config):\n",
    "  command = \"python3\"\n",
    "  command += \" \" + config[\"run_file\"] + \" \"\n",
    "  command += \"--output_dir \" + config[\"output_dir\"] + \" \"\n",
    "  command += \"--model_name_or_path \" + config[\"model_name_or_path\"] + \" \"\n",
    "  command += \"--data_dir \" + config[\"data_dir\"] + \" \"\n",
    "  command += \"--num_train_epochs \" + str(config[\"num_train_epochs\"]) + \" \"\n",
    "  command += \"--per_device_train_batch_size \" + str(config[\"per_device_train_batch_size\"]) + \" \"\n",
    "  command += \"--learning_rate \" + str(config[\"learning_rate\"]) + \" \"\n",
    "  command += \"--max_seq_length \" + str(config[\"max_seq_length\"]) + \" \"\n",
    "\n",
    "\n",
    "  if \"do_train\" in config:\n",
    "    command += \"--do_train \"\n",
    "  if \"do_eval\" in config:\n",
    "    command += \"--do_eval \"\n",
    "  if \"do_predict\" in config:\n",
    "    command += \"--do_predict \"\n",
    "\n",
    "  command += \"--seed \" + str(config[\"seed\"]) + \" \"\n",
    "  if \"umls\" in config:\n",
    "    command += \"--umls \"\n",
    "    command += \"--med_document \" + str(config[\"med_document\"]) + \" \"\n",
    "\n",
    "  command += \"--labels \" + config[\"labels\"]\n",
    "  command += \" --save_steps 50000\"\n",
    "\n",
    "  return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "############################################# \n",
    "Clinical/umls(both 1500000 and 3000000) BERT fine-tuning params\n",
    "- Output dir: ./models/clinicalBert-v1 | ./models/umls-clinicalBert-v1\n",
    "- model_name_or_path: emilyalsentzer/Bio_ClinicalBERT | ../checkpoint/clinicalbert300000\n",
    "- Learning Rate: {2e-5, 3e-5, 5e-5}\n",
    "- Batch size: {16, 32}\n",
    "- Epochs: {20} # ner needs longer training\n",
    "############################################# \n",
    "'''\n",
    "\n",
    "# seeds = [6809, 36275, 5317, 82958, 25368] # five seeds average\n",
    "seeds = [6809] # fine tuning\n",
    "\n",
    "learning_rate_set = [2e-5, 3e-5, 5e-5]\n",
    "batch_size_set = [16, 32]\n",
    "epoch_set = [20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1416685,
     "status": "ok",
     "timestamp": 1594601570529,
     "user": {
      "displayName": "kaxalein M",
      "photoUrl": "",
      "userId": "08160306184891523165"
     },
     "user_tz": 240
    },
    "id": "1Z1feaIecRCC",
    "outputId": "267368cb-79f0-4d81-e1ec-7d4fe09a6909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'dataset/NER/2006/cache*': No such file or directory\n",
      "python3 run_ner.py --output_dir ./models/i2b2_2012/clinicalBert-6809-2020-09-13-23-36-57 --model_name_or_path emilyalsentzer/Bio_ClinicalBERT --data_dir dataset/NER/2006 --num_train_epochs 20 --per_device_train_batch_size 16 --learning_rate 2e-05 --max_seq_length 258 --do_train --do_eval --do_predict --seed 6809 --labels dataset/NER/2006/label.txt --save_steps 50000\n",
      "python3 run_ner.py --output_dir ./models/i2b2_2012/BertBased-6809-2020-09-13-23-37-36 --model_name_or_path bert-base-cased --data_dir dataset/NER/2006 --num_train_epochs 20 --per_device_train_batch_size 16 --learning_rate 2e-05 --max_seq_length 258 --do_train --do_eval --do_predict --seed 6809 --labels dataset/NER/2006/label.txt --save_steps 50000\n"
     ]
    }
   ],
   "source": [
    "path_set = [\n",
    "            (\"./models/i2b2_2012/clinicalBert\", \"emilyalsentzer/Bio_ClinicalBERT\"), \n",
    "            (\"./models/i2b2_2012/BertBased\", \"bert-base-cased\")\n",
    "           ]\n",
    "\n",
    "for seed in seeds:\n",
    "  for lr in learning_rate_set:\n",
    "    for epoch in epoch_set:\n",
    "      for batch_size in batch_size_set:\n",
    "        for path in path_set:\n",
    "          config = {\n",
    "              \"run_file\"                    :     \"run_ner.py\",\n",
    "              \"labels\"                      :     \"dataset/NER/2006/label.txt\",\n",
    "              \"output_dir\"                  :     path[0] + \"-\" +  str(seed)+\"-\"+ datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"),\n",
    "              \"model_name_or_path\"          :     path[1],\n",
    "              \"data_dir\"                    :     \"dataset/NER/2006\",\n",
    "              \"num_train_epochs\"            :     epoch,\n",
    "              \"per_device_train_batch_size\" :     batch_size,\n",
    "              \"learning_rate\"               :     lr,\n",
    "              \"max_seq_length\"              :     258,\n",
    "              \"seed\"                        :     seed,\n",
    "              \"do_train\"                    :     True,\n",
    "              \"do_eval\"                     :     True,\n",
    "              \"do_predict\"                  :     True\n",
    "          }\n",
    "\n",
    "          # Run Downstream tasks with given config\n",
    "          !rm dataset/NER/2006/cache*\n",
    "          command = generate_command(config)\n",
    "          print(command)\n",
    "          subprocess.run(command, shell=True)\n",
    "\n",
    "          # Save config to output dir\n",
    "          with open(config[\"output_dir\"] + '/fine_tune_config.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "          assert \"fine_tune_config.json\" in os.listdir(config[\"output_dir\"])\n",
    "\n",
    "          # delete all checkpoints\n",
    "          for path in os.listdir(config[\"output_dir\"]):\n",
    "            if path.startswith(\"checkpoint\"):\n",
    "              shutil.rmtree(config[\"output_dir\"] + \"/\" +path)\n",
    "            if path.startswith(\"pytorch_model.bin\"):\n",
    "              os.remove(config[\"output_dir\"] + \"/\" +path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 run_ner.py --output_dir ./models/2006-umlsbert/-6809-2020-09-13-23-38-19 --model_name_or_path ../checkpoint/umlsbert --data_dir dataset/NER/2006 --num_train_epochs 20 --per_device_train_batch_size 16 --learning_rate 2e-05 --max_seq_length 258 --do_train --do_eval --do_predict --seed 6809 --umls --med_document voc/vocab_updated.txt --labels dataset/NER/2006/label.txt --save_steps 50000\n"
     ]
    }
   ],
   "source": [
    "path_set = [(\"./models/2006-umlsbert/\", \"../checkpoint/umlsbert\")]\n",
    "\n",
    "for seed in seeds:\n",
    "  for lr in learning_rate_set:\n",
    "    for epoch in epoch_set:\n",
    "      for batch_size in batch_size_set:\n",
    "        for path in path_set:\n",
    "          config = {\n",
    "              \"run_file\"                    :     \"run_ner.py\",\n",
    "              \"labels\"                      :     \"dataset/NER/2006/label.txt\",\n",
    "              \"output_dir\"                  :     path[0] + \"-\" +  str(seed)+\"-\"+ datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"),\n",
    "              \"model_name_or_path\"          :     path[1],\n",
    "              \"data_dir\"                    :     \"dataset/NER/2006\",\n",
    "              \"num_train_epochs\"            :     epoch,\n",
    "              \"per_device_train_batch_size\" :     batch_size,\n",
    "              \"learning_rate\"               :     lr,\n",
    "              \"max_seq_length\"              :     258,\n",
    "              \"seed\"                        :     seed,\n",
    "              \"do_train\"                    :     True,\n",
    "              \"do_eval\"                     :     True,\n",
    "              \"umls\"                        :     True,\n",
    "              \"med_document\"                :     \"voc/vocab_updated.txt\",\n",
    "              \"do_predict\"                  :     True\n",
    "          }\n",
    "\n",
    "          # Run Downstream tasks with given config\n",
    "          !rm dataset/NER/2006/cache*\n",
    "          command = generate_command(config)\n",
    "          print(command)\n",
    "          subprocess.run(command, shell=True)\n",
    "\n",
    "          # Save config to output dir\n",
    "          with open(config[\"output_dir\"] + '/fine_tune_config.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "          assert \"fine_tune_config.json\" in os.listdir(config[\"output_dir\"])\n",
    "\n",
    "          # delete all checkpoints\n",
    "          for path in os.listdir(config[\"output_dir\"]):\n",
    "            if path.startswith(\"checkpoint\"):\n",
    "              shutil.rmtree(config[\"output_dir\"] + \"/\" +path)\n",
    "            if path.startswith(\"pytorch_model.bin\"):\n",
    "              os.remove(config[\"output_dir\"] + \"/\" +path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab_NER_BC5CDR-disease.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
