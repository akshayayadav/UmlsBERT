{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, xml, xml.etree.ElementTree as ET, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CDATA = \"<TEXT><![CDATA[\"\n",
    "END_CDATA   = \"]]></TEXT>\"\n",
    "\n",
    "TAGS        = ['MEDICATION', 'OBSEE', 'SMOKER', 'HYPERTENSION', 'event', 'FAMILY_HIST']\n",
    "\n",
    "def read_xml_file(xml_path, event_tag_type='ALL_CHILDREN', match_text=True):\n",
    "    with open(xml_path, mode='r') as f:\n",
    "        lines = f.readlines()\n",
    "        text, in_text = [], False\n",
    "        for i, l in enumerate(lines):\n",
    "            if START_CDATA in l:\n",
    "                text.append(list(l[l.find(START_CDATA) + len(START_CDATA):]))\n",
    "                in_text = True\n",
    "            elif END_CDATA in l:\n",
    "                text.append(list(l[:l.find(END_CDATA)]))\n",
    "                break\n",
    "            elif in_text:\n",
    "#                 if xml_path.endswith('180-03.xml') and '0808' in l and 'Effingham' in l:\n",
    "#                     print(\"Adjusting known error\")\n",
    "#                     l = l[:9] + ' ' * 4 + l[9:]\n",
    "# #                 elif xml_path.endswith('188-05.xml') and 'Johnson & Johnson' in l:\n",
    "# #                     print(\"Adjusting known error\")\n",
    "# #                     l = l.replace('&', 'and')\n",
    "                text.append(list(l))\n",
    "        \n",
    "    pos_transformer = {}\n",
    "    \n",
    "    linear_pos = 1\n",
    "    for line, sentence in enumerate(text):\n",
    "        for char_pos, char in enumerate(sentence):\n",
    "            pos_transformer[linear_pos] = (line, char_pos)\n",
    "            linear_pos += 1\n",
    "        \n",
    "    try: xml_parsed = ET.parse(xml_path)\n",
    "    except:\n",
    "        print(xml_path)\n",
    "        raise\n",
    "        \n",
    "    tag_containers = xml_parsed.findall('TAGS')\n",
    "    assert len(tag_containers) == 1, \"Found multiple tag sets!\"\n",
    "    tag_container = tag_containers[0]\n",
    "    \n",
    "#     event_tags = tag_container.getchildren() if event_tag_type == 'ALL_CHILDREN' else tag_container.findall('event')\n",
    "    event_tags = tag_container.findall('EVENT')\n",
    "    event_labels = [['O'] * len(sentence) for sentence in text]\n",
    "    for event_tag in event_tags:\n",
    "        base_label = event_tag.attrib['type']\n",
    "        start_pos, end_pos, event_text = event_tag.attrib['start'], event_tag.attrib['end'], event_tag.attrib['text']\n",
    "        start_pos, end_pos = int(start_pos)+1, int(end_pos)\n",
    "        event_text = ' '.join(event_text.split())\n",
    "#         if event_text == \"0808 O’neil’s Court\":\n",
    "#             print(\"Adjusting known error\")\n",
    "#             end_pos -= 4\n",
    "#         if event_text == 'Johnson and Johnson' and xml_path.endswith('188-05.xml'):\n",
    "#             print(\"Adjusting known error\")\n",
    "#             event_text = 'Johnson & Johnson'\n",
    "        \n",
    "\n",
    "        (start_line, start_char), (end_line, end_char) = pos_transformer[start_pos], pos_transformer[end_pos]\n",
    "            \n",
    "        obs_text = []\n",
    "        for line in range(start_line, end_line+1):\n",
    "            t = text[line]\n",
    "            s = start_char if line == start_line else 0\n",
    "            e = end_char if line == end_line else len(t)\n",
    "            obs_text.append(''.join(t[s:e+1]).strip())\n",
    "        obs_text = ' '.join(obs_text)\n",
    "        obs_text = ' '.join(obs_text.split())\n",
    "        \n",
    "        if '&apos;' in obs_text and '&apos;' not in event_text: event_text = event_text.replace(\"'\", \"&apos;\")\n",
    "        if '&quot;' in obs_text and '&quot;' not in event_text: event_text = event_text.replace('\"', '&quot;')\n",
    "              \n",
    "        if match_text: assert obs_text == event_text, (\n",
    "            (\"Texts don't match! %s v %s\" % (event_text, obs_text)) + '\\n' + str((\n",
    "                start_pos, end_pos, line, s, e, t, xml_path\n",
    "            ))\n",
    "        )\n",
    "            \n",
    "        if base_label.strip() == '': continue\n",
    "        \n",
    "        event_labels[end_line][end_char]     = 'I-%s' % base_label\n",
    "        event_labels[start_line][start_char] = 'B-%s' % base_label\n",
    "        \n",
    "        for line in range(start_line, end_line+1):\n",
    "            t = text[line]\n",
    "            s = start_char+1 if line == start_line else 0\n",
    "            e = end_char-1 if line == end_line else len(t)-1\n",
    "            for i in range(s, e+1): event_labels[line][i] = 'I-%s' % base_label\n",
    "\n",
    "    return text, event_labels\n",
    "    \n",
    "def merge_into_words(text_by_char, all_labels_by_char):\n",
    "    assert len(text_by_char) == len(all_labels_by_char), \"Incorrect # of sentences!\"\n",
    "    \n",
    "    N = len(text_by_char)\n",
    "    \n",
    "    text_by_word, all_labels_by_word = [], []\n",
    "    \n",
    "    for sentence_num in range(N):\n",
    "        sentence_by_char = text_by_char[sentence_num]\n",
    "        labels_by_char   = all_labels_by_char[sentence_num]\n",
    "        \n",
    "        assert len(sentence_by_char) == len(labels_by_char), \"Incorrect # of chars in sentence!\"\n",
    "        S = len(sentence_by_char)\n",
    "        \n",
    "        if labels_by_char == (['O'] * len(sentence_by_char)):\n",
    "            sentence_by_word = ''.join(sentence_by_char).split()\n",
    "            labels_by_word   = ['O'] * len(sentence_by_word)\n",
    "        else: \n",
    "            sentence_by_word, labels_by_word = [], []\n",
    "            text_chunks, labels_chunks = [], []\n",
    "            s = 0\n",
    "            for i in range(S):\n",
    "                if i == S-1:\n",
    "                    text_chunks.append(sentence_by_char[s:])\n",
    "                    labels_chunks.append(labels_by_char[s:])\n",
    "                elif labels_by_char[i] == 'O': continue\n",
    "                else:\n",
    "                    if i > 0 and labels_by_char[i-1] == 'O':\n",
    "                        text_chunks.append(sentence_by_char[s:i])\n",
    "                        labels_chunks.append(labels_by_char[s:i])\n",
    "                        s = i\n",
    "                    if labels_by_char[i+1] == 'O' or labels_by_char[i+1][2:] != labels_by_char[i][2:]:\n",
    "                        text_chunks.append(sentence_by_char[s:i+1])\n",
    "                        labels_chunks.append(labels_by_char[s:i+1])\n",
    "                        s = i+1\n",
    "                \n",
    "            for text_chunk, labels_chunk in zip(text_chunks, labels_chunks):\n",
    "                assert len(text_chunk) == len(labels_chunk), \"Bad Chunking (len)\"\n",
    "                assert len(text_chunk) > 0, \"Bad chunking (len 0)\" + str(text_chunks) + str(labels_chunks)\n",
    "                \n",
    "                labels_set = set(labels_chunk)\n",
    "                assert labels_set == set(['O']) or (len(labels_set) <= 3 and 'O' not in labels_set), (\n",
    "                    (\"Bad chunking (contents) %s\" % ', '.join(labels_set))+ str(text_chunks) + str(labels_chunks)\n",
    "                )\n",
    "                \n",
    "                text_chunk_by_word = ''.join(text_chunk).split()\n",
    "                W = len(text_chunk_by_word)\n",
    "                if W == 0: \n",
    "#                     assert labels_set == set(['O']), \"0-word chunking and non-0 label!\" + str(\n",
    "#                         text_chunks) + str(labels_chunks\n",
    "#                     )\n",
    "                    continue\n",
    "                \n",
    "                if labels_chunk[0] == 'O': labels_chunk_by_word = ['O'] * W\n",
    "                elif W == 1:               labels_chunk_by_word = [labels_chunk[0]]\n",
    "                elif W == 2:               labels_chunk_by_word = [labels_chunk[0], labels_chunk[-1]]\n",
    "                else:                      labels_chunk_by_word = [\n",
    "                        labels_chunk[0]\n",
    "                    ] + [labels_chunk[1]] * (W - 2) + [\n",
    "                        labels_chunk[-1]\n",
    "                    ]\n",
    "                    \n",
    "                sentence_by_word.extend(text_chunk_by_word)\n",
    "                labels_by_word.extend(labels_chunk_by_word)\n",
    "\n",
    "        assert len(sentence_by_word) == len(labels_by_word), \"Incorrect # of words in sentence!\"    \n",
    "        \n",
    "        if len(sentence_by_word) == 0: continue\n",
    "            \n",
    "        text_by_word.append(sentence_by_word)\n",
    "        all_labels_by_word.append(labels_by_word)\n",
    "    return text_by_word, all_labels_by_word\n",
    "\n",
    "def reprocess_event_labels(folders, base_path='.', event_tag_type='event', match_text=True, dev_set_size=None):\n",
    "    all_texts_by_patient, all_labels_by_patient = {}, {}\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_dir = os.path.join(base_path, folder)\n",
    "        xml_filenames = [x for x in os.listdir(folder_dir) if x.endswith('xml')]\n",
    "        for xml_filename in xml_filenames:\n",
    "            try:\n",
    "                patient_num = int(xml_filename[:-4])\n",
    "                xml_filepath = os.path.join(folder_dir, xml_filename)\n",
    "\n",
    "                text_by_char, labels_by_char = read_xml_file(\n",
    "                    xml_filepath,\n",
    "                    event_tag_type=event_tag_type,\n",
    "                    match_text=match_text\n",
    "                )\n",
    "                text_by_word, labels_by_word = merge_into_words(text_by_char, labels_by_char)\n",
    "\n",
    "                if patient_num not in all_texts_by_patient:\n",
    "                    all_texts_by_patient[patient_num] = []\n",
    "                    all_labels_by_patient[patient_num] = []\n",
    "\n",
    "                all_texts_by_patient[patient_num].extend(text_by_word)\n",
    "                all_labels_by_patient[patient_num].extend(labels_by_word)\n",
    "            except:\n",
    "                print(xml_filename)\n",
    "            \n",
    "    patients = set(all_texts_by_patient.keys())\n",
    "    \n",
    "    if dev_set_size is None: train_patients, dev_patients = list(patients), []\n",
    "    else:\n",
    "        N_train = int(len(patients) * (1-dev_set_size))\n",
    "        patients_random = np.random.permutation(list(patients))\n",
    "        train_patients = list(patients_random[:N_train])\n",
    "        dev_patients   = list(patients_random[N_train:])\n",
    "    \n",
    "    train_texts, train_labels = [], []\n",
    "    dev_texts, dev_labels = [], []\n",
    "    \n",
    "    for patient_num in train_patients:\n",
    "        train_texts.extend(all_texts_by_patient[patient_num])\n",
    "        train_labels.extend(all_labels_by_patient[patient_num])\n",
    "\n",
    "    for patient_num in dev_patients:\n",
    "        dev_texts.extend(all_texts_by_patient[patient_num])\n",
    "        dev_labels.extend(all_labels_by_patient[patient_num])\n",
    "\n",
    "\n",
    "    train_out_text_by_sentence = []\n",
    "    for text, labels in zip(train_texts, train_labels):\n",
    "        train_out_text_by_sentence.append('\\n'.join('%s %s' % x for x in zip(text, labels)))\n",
    "    dev_out_text_by_sentence = []\n",
    "    for text, labels in zip(dev_texts, dev_labels):\n",
    "        dev_out_text_by_sentence.append('\\n'.join('%s %s' % x for x in zip(text, labels)))\n",
    "\n",
    "    return '\\n\\n'.join(train_out_text_by_sentence), '\\n\\n'.join(dev_out_text_by_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./2012-07-15.original-annotation.release/382.xml\n",
      "382.xml\n",
      "./2012-07-15.original-annotation.release/152.xml\n",
      "152.xml\n",
      "./2012-07-15.original-annotation.release/143.xml\n",
      "143.xml\n",
      "./2012-07-15.original-annotation.release/422.xml\n",
      "422.xml\n",
      "./2012-07-15.original-annotation.release/272.xml\n",
      "272.xml\n",
      "./2012-07-15.original-annotation.release/547.xml\n",
      "547.xml\n",
      "./2012-07-15.original-annotation.release/23.xml\n",
      "23.xml\n",
      "./2012-07-15.original-annotation.release/807.xml\n",
      "807.xml\n"
     ]
    }
   ],
   "source": [
    "final_train_text, final_dev_text = reprocess_event_labels(\n",
    "    ['2012-07-15.original-annotation.release'], dev_set_size=0.1, match_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./2012-08-08.test-data.event-timex-groundtruth/xml/527.xml\n",
      "527.xml\n",
      "./2012-08-08.test-data.event-timex-groundtruth/xml/53.xml\n",
      "53.xml\n",
      "./2012-08-08.test-data.event-timex-groundtruth/xml/687.xml\n",
      "687.xml\n",
      "./2012-08-08.test-data.event-timex-groundtruth/xml/802.xml\n",
      "802.xml\n",
      "./2012-08-08.test-data.event-timex-groundtruth/xml/397.xml\n",
      "397.xml\n",
      "./2012-08-08.test-data.event-timex-groundtruth/xml/627.xml\n",
      "627.xml\n"
     ]
    }
   ],
   "source": [
    "test_text, _ = reprocess_event_labels(\n",
    "    ['2012-08-08.test-data.event-timex-groundtruth/xml'], match_text=False, dev_set_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission B-OCCURRENCE\n",
      "Date O\n",
      ": O\n",
      "\n",
      "2013-10-27 O\n",
      "\n",
      "Discharge B-OCCURRENCE\n",
      "Date O\n",
      ": O\n",
      "\n",
      "2013-11-03 O\n",
      "\n",
      "Service O\n",
      ": O\n",
      "\n",
      "MEDICINE O\n",
      "\n",
      "History O\n",
      "of O\n",
      "Present O\n",
      "Illness O\n",
      ": O\n",
      "\n",
      "42 O\n",
      "year O\n",
      "old O\n",
      "female O\n",
      "with O\n",
      "h/o O\n",
      "cholangiocarcinoma B-PROBLEM\n",
      "dx O\n",
      "in O\n",
      "2009 O\n",
      "s/p O\n",
      "resection B-TREATMENT\n",
      ", O\n",
      "with O\n",
      "recent B-TEST\n",
      "CT I-TEST\n",
      "showing B-EVIDENTIAL\n",
      "met B-PROBLEM\n",
      "cholangiocarcinoma I-PROBLEM\n",
      "in O\n",
      "9/2004 O\n",
      ". O\n",
      "\n",
      "Pt O\n",
      "was O\n",
      "recently O\n",
      "admitted B-OCCURRENCE\n",
      "for O\n",
      "fever B-PROBLEM\n",
      "due O\n",
      "to O\n",
      "cholangitis B-PROBLEM\n",
      "on O\n"
     ]
    }
   ],
   "source": [
    "print(final_train_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMISSION B-OCCURRENCE\n",
      "DATE O\n",
      ": O\n",
      "\n",
      "03/11/2002 O\n",
      "\n",
      "DISCHARGE B-OCCURRENCE\n",
      "DATE O\n",
      ": O\n",
      "\n",
      "03/14/2002 O\n",
      "\n",
      "DISCHARGE B-OCCURRENCE\n",
      "DATE O\n",
      ": O\n",
      "\n",
      "03/14/2002 O\n",
      "\n",
      "HISTORY O\n",
      "OF O\n",
      "PRESENT O\n",
      "ILLNESS O\n",
      ": O\n",
      "\n",
      "This O\n",
      "is O\n",
      "a O\n",
      "62-year-old O\n",
      "hospice O\n",
      "chaplain O\n",
      "who O\n",
      "was O\n",
      "referred B-OCCURRENCE\n",
      "by O\n",
      "Dr. O\n",
      "Tomedankell O\n",
      "Flowayles O\n",
      "and O\n",
      "Dr. O\n",
      "Es O\n",
      "Oarekote O\n",
      "for O\n",
      "evaluation B-TEST\n",
      "of O\n",
      "his B-PROBLEM\n",
      "right I-PROBLEM\n",
      "hip \n"
     ]
    }
   ],
   "source": [
    "print(final_dev_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMISSION B-OCCURRENCE\n",
      "DATE O\n",
      ": O\n",
      "\n",
      "10/14/96 O\n",
      "\n",
      "DISCHARGE B-OCCURRENCE\n",
      "DATE O\n",
      ": O\n",
      "\n",
      "10/27/96 O\n",
      "date O\n",
      "of O\n",
      "birth B-OCCURRENCE\n",
      "; O\n",
      "September O\n",
      "30 O\n",
      ", O\n",
      "1917 O\n",
      "\n",
      "THER O\n",
      "PROCEDURES O\n",
      ": O\n",
      "\n",
      "arterial B-TEST\n",
      "catheterization I-TEST\n",
      "on O\n",
      "10/14/96 O\n",
      ", O\n",
      "head B-TEST\n",
      "CT I-TEST\n",
      "scan I-TEST\n",
      "on O\n",
      "10/14/96 O\n",
      "\n",
      "HISTORY O\n",
      "AND O\n",
      "REASON O\n",
      "FOR O\n",
      "HOSPITALIZATION O\n",
      ": O\n",
      "\n",
      "Granrivern O\n",
      "Call O\n",
      "is O\n",
      "a O\n",
      "79-year-old O\n",
      "right O\n",
      "han\n"
     ]
    }
   ],
   "source": [
    "print(test_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for s in final_train_text, final_dev_text, test_text:\n",
    "    for line in s.split('\\n'):\n",
    "        if line == '': continue\n",
    "        label = line.split()[-1]\n",
    "        assert label == 'O' or label.startswith('B-') or label.startswith('I-'), \"label wrong! %s\" % label\n",
    "        if label not in labels: labels[label] = 1\n",
    "        else: labels[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-OCCURRENCE': 5351,\n",
       " 'O': 107645,\n",
       " 'B-PROBLEM': 8717,\n",
       " 'B-TREATMENT': 6571,\n",
       " 'B-TEST': 4477,\n",
       " 'I-TEST': 5655,\n",
       " 'B-EVIDENTIAL': 1273,\n",
       " 'I-PROBLEM': 12870,\n",
       " 'I-OCCURRENCE': 3258,\n",
       " 'I-TREATMENT': 6300,\n",
       " 'B-CLINICAL_DEPT': 1537,\n",
       " 'I-CLINICAL_DEPT': 2858,\n",
       " 'I-EVIDENTIAL': 82}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../../NER/2012/label.txt\", \"w\")\n",
    "for label in labels:\n",
    "    f.write(label+\"\\n\")\n",
    "f.close()\n",
    "\n",
    "with open('../../NER/2012/train.txt', mode='w') as f:\n",
    "    f.write(final_train_text)\n",
    "with open('../../NER/2012/dev.txt', mode='w') as f:\n",
    "    f.write(final_dev_text)\n",
    "with open('../../NER/2012/test.txt', mode='w') as f:\n",
    "    f.write(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
